{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RnyrGz6zrQK",
        "outputId": "05957467-b6ee-45f6-e158-2a107a39804c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9393939393939394\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "x = train['Message_body']\n",
        "y = train[\"Label\"]\n",
        "x_train, x_test,y_train, y_test = train_test_split(x,y,test_size = 0.2)\n",
        "\n",
        "punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "def remove_punctuation(text):\n",
        "  for char in text:\n",
        "    if char in punct:\n",
        "      text = text.replace(char,'')\n",
        "  return text\n",
        "\n",
        "x_train = x_train.apply(remove_punctuation)\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords') # do this only once\n",
        "nltk.download('punkt') # do this only once\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  clean_text = []\n",
        "  for word in word_tokenize(text):\n",
        "    if not word in stopwords.words():\n",
        "      clean_text.append(word)\n",
        "  return ' '.join(clean_text)\n",
        "\n",
        "x_train = x_train.apply(remove_stopwords)\n",
        "cv = CountVectorizer()\n",
        "features = cv.fit_transform(x_train)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "model= MLPClassifier(hidden_layer_sizes=(20,25,20),alpha=0.001,max_iter=200,activation='relu')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(features,y_train)\n",
        "\n",
        "features_test = cv.transform(x_test)\n",
        "print(model.score(features_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "ytest=test['Message_body']\n",
        "\n",
        "\n",
        "features = cv.transform(ytest)\n",
        "pred=model.predict(features)\n",
        "test['Label']=pred"
      ],
      "metadata": {
        "id": "Zg1qD_yTz0nz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Submission = test[['Id','Label']]\n",
        "Submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "AEmgwEAHz-sW"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}